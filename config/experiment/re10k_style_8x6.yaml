# @package _global_

defaults:
  - /dataset@_group_.re10k_style: re10k_style
  - override /model/encoder: noposplat_token_style
  - override /model/encoder/backbone: croco_enc
  - override /loss: [style]

wandb:
  project: noposplat_xiang_token_style_debug
  name: re10k
  tags: [re10k, 256x256]

model:
  encoder:
    gs_params_head_type: dpt_gs
    gs_sh_head_type: dpt
    pose_free: true
    intrinsics_embed_loc: encoder
    intrinsics_embed_type: token
    # pretrained_weights: 'ckpts/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth'
    # need pretrained intrinsics encoder
    pretrained_weights: "/ssdwork/datasets/weights/re10k.ckpt"
    stylized: true
  decoder:
    make_scale_invariant: true

dataset:
  re10k_style:
    name: re10k_style
    style_root: "/ssdwork/datasets/wikiart_combine/images_combine"
    view_sampler:
      warm_up_steps: 25000  # 9375 × 2.67

optimizer:
  lr: 2e-4                 # 2e-4 × sqrt(0.375)
  warm_up_steps: 333        # 125 × 2.67
  backbone_lr_multiplier: 0.1

data_loader:
  train:
    batch_size: 6           # 每卡 batch size = 6

train:
  identity_loss: true

trainer:
  max_steps: 50000          # 18751 × 2.67
  val_check_interval: 500  # 500 × 2.67

checkpointing:
  every_n_train_steps: 25000  # 9375 × 2.67
  load: 'outputs/exp_re10k_token_style_pretrain_pre-distilled/2025-04-21_21-39-54/checkpoints/epoch_0-step_25000.ckpt'