# @package _global_

defaults:
  - /dataset@_group_.re10k: re10k
  - /dataset@_group_.dl3dv: dl3dv
  - override /model/encoder: noposplat
  - override /model/encoder/backbone: croco
  - override /loss: [mse, lpips]

wandb:
  name: re10k_dl3dv
  tags: [re10k_dl3dv, 256x256]

model:
  encoder:
    gs_params_head_type: dpt_gs
    pose_free: true
    intrinsics_embed_loc: encoder
    intrinsics_embed_type: token
    pretrained_weights: 'ckpts/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth'

dataset:
  re10k:
    view_sampler:
      warm_up_steps: 150_000
  dl3dv:
    view_sampler:
      warm_up_steps: 150_000

optimizer:
  lr: 1e-4
  warm_up_steps: 2000
  backbone_lr_multiplier: 0.1

data_loader:
  train:
    batch_size: 4  # 8 for each dataset, since we have 2 datasets, the total batch size is 16

trainer:
  max_steps: 300_001
  val_check_interval: 2000

checkpointing:
  every_n_train_steps: 150_000
